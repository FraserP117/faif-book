{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent solutions to most likely hidden state by MLE/MAP estimation\n",
    "\n",
    "This notebook shows how one can use maximum likelihood estimation (MLE) or maximum a posteriori (MAP) estimation to find the most likely hidden state given some sensory observation via gradient descent instead of using the analytic solution.\n",
    "\n",
    "==========================================================================\n",
    "\n",
    "* **Notebook dependencies**:\n",
    "    * ...\n",
    "\n",
    "* **Content**: Jupyter notebook accompanying Chapter 2 of the textbook \"Fundamentals of Active Inference\"\n",
    "\n",
    "* **Author**: Sanjeev Namjoshi (sanjeev.namjoshi@gmail.com)\n",
    "\n",
    "* **Version**: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from torch.distributions import Normal\n",
    "from types import SimpleNamespace\n",
    "from typing import Union\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.utils import create_environment\n",
    "\n",
    "mpl.style.use(\"seaborn-deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last notebook examined how to find the most likely hidden state estimate after observing the sensory data based on just using the model likelihood (MLE) or the likelihood and the prior (MAP estimation). The result was an analytic update equation for the hidden state. \n",
    "\n",
    "We now turn our attention to the gradient descent solution to this problem which is an iterative optimization based approach. This demonstration also introduces the concept of gradient descent which will be important in the chapters that follow.\n",
    "\n",
    "First we generate 500 data points under a linear generating function as we have done before.\n",
    "\n",
    "**Note**: we will be using the `torch` package to perform gradient descent so we will need to be using Torch tensors instead of NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "env_params = {\n",
    "    \"beta_0_star\" : 3,    # Linear parameter intercept\n",
    "    \"beta_1_star\" : 2,    # Linear parameter slope\n",
    "    \"y_star_std\"  : 0.5   # Standard deviation of sensory data\n",
    "}\n",
    "\n",
    "# Initialize environment and agent\n",
    "env = create_environment(name=\"static_linear\", params=env_params)\n",
    "\n",
    "# Generate data for three different x_star values\n",
    "x_star  = 2                                          # 3 different external states\n",
    "N       = 500                                        # Number of samples\n",
    "y       = np.zeros(N)                                # Empty array for i=20 samples\n",
    "\n",
    "# Generate\n",
    "for i in range(N):\n",
    "    y[i] = env.generate(x_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform gradient descent we need a loss function. We will use the loss function described in the previous chapter. These are different for MLE and MAP.\n",
    "* MLE will use the negative log likelihood.\n",
    "* MAP will use the negative log likelihood minus the log prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_function(beta_0: float, beta_1: float, x: float) -> float:\n",
    "    return beta_1 * x + beta_0\n",
    "\n",
    "def mle_objective(x: float, y: Union[float, np.ndarray]) -> np.ndarray:\n",
    "    \n",
    "    # Parameters\n",
    "    beta_0 = 3      # Linear generating function intercept\n",
    "    beta_1 = 2      # Linear generating function slope\n",
    "    var_y  = 0.5    # Likelihood variance\n",
    "    \n",
    "    # Linear genearting function\n",
    "    mu_y   = generating_function(beta_0=beta_0, beta_1=beta_1, x=x)\n",
    "    \n",
    "    # Calculate log-likelihood over samples\n",
    "    likelihood_i = norm.pdf(y, loc=mu_y, scale=np.sqrt(var_y))\n",
    "    log_likelihood_i = np.log(likelihood_i)\n",
    "    log_likelihood = log_likelihood_i.sum(axis=0)\n",
    "    \n",
    "    return -log_likelihood   \n",
    "    \n",
    "def map_objective(x: float, y: Union[float, np.ndarray]) -> np.ndarray:\n",
    "        \n",
    "    # Parameters\n",
    "    beta_0 = 3      # Linear generating function intercept\n",
    "    beta_1 = 2      # Linear generating function slope\n",
    "    var_y  = 0.5    # Likelihood variance\n",
    "    m_x    = 2      # Prior mean\n",
    "    s_x    = 0.25   # Prior variance\n",
    "    \n",
    "    # Linear generating function\n",
    "    mu_y   = generating_function(beta_0=beta_0, beta_1=beta_1, x=x)\n",
    "    \n",
    "    # Calculate log-likelihood over samples\n",
    "    likelihood_i = norm.pdf(y, loc=mu_y, scale=np.sqrt(var_y))\n",
    "    log_likelihood_i = np.log(likelihood_i)\n",
    "    log_likelihood = log_likelihood_i.sum(axis=0)\n",
    "    \n",
    "    # Calculate log-prior\n",
    "    log_prior = norm.pdf(x, loc=m_x, scale=np.sqrt(s_x))\n",
    "    \n",
    "    \n",
    "    return -(log_likelihood + log_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to perform **gradient descent** over our objective function. Let's refer to the objectives in question as $\\mathcal{F}_{MLE}$ and $\\mathcal{F}_{MAP}$ for MLE and MAP respectively. The aim is to find the minima of this objective function. This minima is the point where the negative log likelihood of the data is minimized (or the negative log likelihood of the data plus log prior assumptions for MAP). This represents the mode of the posterior. Since we are using Gaussian probability distributions, which are quadratic in construction, we will have a well-behaved objective function with a single minima. For each iteration $j \\in \\left \\{0, \\dots, J \\right \\}$ we perform the following update for MLE or MAP:\n",
    "\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        \\textbf{MLE}: \\hspace{5mm} x^{(j+1)} &\\gets x^{(j)} - \\kappa \\frac{\\partial \\mathcal{F}_{MLE}}{\\partial x} \\\\\n",
    "        \\textbf{MAP}: \\hspace{5mm} x^{(j+1)} &\\gets x^{(j)} - \\kappa \\frac{\\partial \\mathcal{F}_{MAP}}{\\partial x}\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\kappa$ (kappa) is a **learning rate**. This tells us that we make iterative updates to our running best guess about the value of $x$ by moving in the direction of steepest descent along our loss function, where steepest descent is calculated from the partial derivative of the loss function with respect to $x$. $\\kappa$ tells us how big our step down the gradient will be and we are free to specify this hyperparameter ourselves.\n",
    "\n",
    "This process has no clear termination so when do we stop? We could pick a hard stopping limit, say 100 iterations. Or, we could specify some tolerance. When the updates to the best guess of $x^{(j)}$ at the j-th iteration does not change within some tolerance we know that the process has essentially \"flat-lined\" or, more properly, **converged** at a local minima. In our case, since we are using a quadratic loss function, this local minima will be the global minima.\n",
    "\n",
    "Note that we must also choose our initial value for $x$ before kicking off the process. We could choose this randomly or use some prior information about a best guess of where to start. Gradient descent is very sensitive to both the initialization and learning rate (kappa) and the performance of the algorithm depends highly on our choice. For our simple case these settings do not matter as much.\n",
    "\n",
    "Below we define the gradient descent function. We will use the `torch` package for this purpose which contains functions for **auto-differentiation**. In other words, this package will allow us to easily calculate the partial derivative of the loss function so we do not have to do it by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(kappa: float, \n",
    "                     n_iterations: int, \n",
    "                     x: float, \n",
    "                     obj: callable):\n",
    "    \n",
    "    print(f\"Initializing x at {x}.\")\n",
    "    \n",
    "    # Initialize empty history arrays\n",
    "    x_history    = torch.zeros(n_iterations)\n",
    "    loss_history = torch.zeros(n_iterations)\n",
    "    \n",
    "    # Calculate loss at initialization\n",
    "    loss = obj(x, y)\n",
    "    \n",
    "    # Add initialization values to history (j=0)\n",
    "    x_history[0]    = x\n",
    "    loss_history[0] = loss\n",
    "    \n",
    "    # Turn x into a Torch tensor which is differentiable\n",
    "    x = torch.tensor(x, requires_grad=True)\n",
    "    \n",
    "    for j in range(n_iterations):\n",
    "        obj_x = obj(x, y)\n",
    "        obj_x.backward()\n",
    "        \n",
    "        # Perform gradient descent\n",
    "        with torch.no_grad():\n",
    "            x -= (kappa * x.grad)\n",
    "            x.grad.zero_()   # Zero out the gradients\n",
    "        \n",
    "        # Recalculate loss\n",
    "        loss = obj(x[0], y)\n",
    "        \n",
    "        # Append to history\n",
    "        x_history[j] = x[0]\n",
    "        loss_history[j] = loss\n",
    "\n",
    "    return x_history, loss_history\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing x at 5.0.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3631/2082358909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gradient_descent(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mn_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     obj = mle_objective)\n",
      "\u001b[0;32m/tmp/ipykernel_3631/1163542195.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(kappa, n_iterations, x, obj)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mobj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mobj_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3631/1917624907.py\u001b[0m in \u001b[0;36mmle_objective\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Calculate log-likelihood over samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mlikelihood_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlog_likelihood_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihood_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_likelihood_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_env_1/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \"\"\"\n\u001b[1;32m   1866\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0mdtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ds_env_1/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "gradient_descent(\n",
    "    kappa = 0.000001, \n",
    "    n_iterations = 100, \n",
    "    x = 5., \n",
    "    obj = mle_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
