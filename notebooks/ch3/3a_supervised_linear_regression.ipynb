{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised linear regression\n",
    "\n",
    "This notebook shows how to use the agent to perform supervised linear regression. The output is compared to results from the `scikit-learn` package.\n",
    "\n",
    "==========================================================================\n",
    "\n",
    "* **Notebook dependencies**:\n",
    "    * ...\n",
    "\n",
    "* **Content**: Jupyter notebook accompanying Chapter 3 of the textbook \"Fundamentals of Active Inference\"\n",
    "\n",
    "* **Author**: Sanjeev Namjoshi (sanjeev.namjoshi@gmail.com)\n",
    "\n",
    "* **Version**: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mpl.style.use(\"seaborn-deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a linear regression agent that can learn from test data and $y$ given some new $X$. This is a classic use case of linear regression in a supervised learning setting.\n",
    "\n",
    "We use the same environment as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticEnvironment:\n",
    "    def __init__(self, params: dict) -> None:\n",
    "        self.params = SimpleNamespace(**params)\n",
    "        \n",
    "    def _noise(self):\n",
    "        return np.random.normal(loc=0, scale=self.params.y_star_std)\n",
    "    \n",
    "    def _generating_function(self, x_star: np.array) -> float:\n",
    "        return x_star.T @ self.params.theta_star\n",
    "    \n",
    "    def generate(self, x_star: float) -> float:\n",
    "        x_star = np.insert(x_star, 0, 1)\n",
    "        return self._generating_function(x_star) + self._noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent now has a `predict()` function that attempts to predict $y$ given some new $X$ input. All this function does is run X_star through the generating function to obtain $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegressionAgent:\n",
    "    def __init__(self) -> None:\n",
    "        ...\n",
    "        \n",
    "    def mle_theta(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return np.linalg.pinv(X) @ y\n",
    "    \n",
    "    def build_data_matrix(self, X_star: np.ndarray) -> np.ndarray:\n",
    "        return np.insert(X_star, 0, 1, axis=1) \n",
    "    \n",
    "    def learn_parameters(self, X_star: np.ndarray, y: np.ndarray) -> None:\n",
    "        X = self.build_data_matrix(X_star)\n",
    "        self.theta = self.mle_theta(X, y)\n",
    "        \n",
    "    def _generating_function(self, X: np.array) -> float:\n",
    "        return X @ self.theta\n",
    "        \n",
    "    def predict(self, X_star_new: np.ndarray):\n",
    "        X = self.build_data_matrix(X_star_new)\n",
    "        self.y_pred = self._generating_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate data from the environment first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "env_params = {\n",
    "    \"theta_star\"  : np.array([3., 2., 4., 5., 6.]), \n",
    "    \"y_star_std\"  : 1.,                   # Standard deviation of sensory data\n",
    "    \"C\"           : 5                     # Number of parameters\n",
    "}\n",
    "\n",
    "# Initialize environment with parameters\n",
    "env = StaticEnvironment(params=env_params)\n",
    "\n",
    "# Generate data \n",
    "N       = 1000                                        # Number of samples\n",
    "C       = env_params[\"theta_star\"].shape[0]          # Number of parameters\n",
    "x_range = np.linspace(start=0.01, stop=5, num=500)   # Support of x\n",
    "X_star  = np.random.choice(x_range, size=(N, C-1))   # N random external states\n",
    "y       = np.zeros(N)                                # Empty array for N data samples\n",
    "\n",
    "# Generate N samples\n",
    "for idx, x in enumerate(X_star):\n",
    "    y[idx] = env.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the agent, learn parameters, generate more data, and then predict $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent and learn parameters\n",
    "agent = MultipleLinearRegressionAgent()\n",
    "agent.learn_parameters(X_star, y)\n",
    "\n",
    "# Generate new data\n",
    "X_star_new = np.random.choice(x_range, size=(N, C-1))   # N random external states\n",
    "y_new      = np.zeros(N)                                # Empty array for N data samples\n",
    "\n",
    "# Generate N samples\n",
    "for idx, x_new in enumerate(X_star_new):\n",
    "    y_new[idx] = env.generate(x_new)\n",
    "\n",
    "# Predict new y\n",
    "agent.predict(X_star_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance we use the root mean-squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995016143212305"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_new, agent.y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that the agent is, on average, off by 1 unit of light intensity from the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare these results with `scikit-learn`'s build in linear regression fitter. One can think of the `learn_parameters()` function in our agent as equivalent to the `fit()` function in `scikit-learn`. First we generate the $X$ and $y$ from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "env_params = {\n",
    "    \"theta_star\"  : np.array([3., 2., 4., 5., 6.]), \n",
    "    \"y_star_std\"  : 1.,                   # Standard deviation of sensory data\n",
    "    \"C\"           : 5                     # Number of parameters\n",
    "}\n",
    "\n",
    "# Initialize environment with parameters\n",
    "env = StaticEnvironment(params=env_params)\n",
    "\n",
    "# Generate data \n",
    "N       = 1000                                        # Number of samples\n",
    "C       = env_params[\"theta_star\"].shape[0]          # Number of parameters\n",
    "x_range = np.linspace(start=0.01, stop=5, num=500)   # Support of x\n",
    "X_star  = np.random.choice(x_range, size=(N, C-1))   # N random external states\n",
    "y       = np.zeros(N)                                # Empty array for N data samples\n",
    "\n",
    "# Generate N samples\n",
    "for idx, x in enumerate(X_star):\n",
    "    y[idx] = env.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_star, y, test_size=0.3, random_state=4885)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run linear regression with `sklearn` and compare the results to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn RMSE: 1.0061497781750777.\n",
      "Agent RMSE: 1.0061497781750837.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" scikit-learn \"\"\"\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "skl_y_pred = lr.predict(X_test)\n",
    "skl_rmse = rmse(y_test, skl_y_pred)\n",
    "\n",
    "\"\"\" Our agent \"\"\"\n",
    "agent = MultipleLinearRegressionAgent()\n",
    "agent.learn_parameters(X_train, y_train)\n",
    "agent.predict(X_test)\n",
    "agent_y_pred = agent.y_pred\n",
    "agent_rmse = rmse(y_test, agent_y_pred)\n",
    "\n",
    "# Results\n",
    "print(f\"sklearn RMSE: {skl_rmse}.\")\n",
    "print(f\"Agent RMSE: {agent_rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to see how close the agent's prediction and sklearn's prediction deviated from one another, we can use the RMSE again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.305980954218592e-14"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(skl_y_pred, agent_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is almost no error between the output of the agent and the output of sklearn. Let's also examine the parameter estimates.\n",
    "\n",
    "**Note**: Scikit-learn splits apart the intercept from the rest of the parameters in its class variables so we need to gather them together into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn parameter estimate: [3.088 1.972 3.99  4.998 5.986].\n",
      "Agent parameter estimate  : [3.088 1.972 3.99  4.998 5.986].\n"
     ]
    }
   ],
   "source": [
    "print(f\"sklearn parameter estimate: {np.round(np.insert(lr.coef_, 0, lr.intercept_),3)}.\")\n",
    "print(f\"Agent parameter estimate  : {np.round(agent.theta, 3)}.\")      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
