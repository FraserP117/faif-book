{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression\n",
    "\n",
    "Using the agent to infer linear generating function parameters instead of hidden states via gradient descent instead of analytic calculation of the maximum likelihood estimate.\n",
    "\n",
    "==========================================================================\n",
    "\n",
    "* **Notebook dependencies**:\n",
    "    * ...\n",
    "\n",
    "* **Content**: Jupyter notebook accompanying Chapter 3 of the textbook \"Fundamentals of Active Inference\"\n",
    "\n",
    "* **Author**: Sanjeev Namjoshi (sanjeev.namjoshi@gmail.com)\n",
    "\n",
    "* **Version**: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import norm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "mpl.style.use(\"seaborn-deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we show how we can estimate the parameter values for an arbitrary number of $\\beta$'s. In other words, all of our $\\beta$'s of interest will be collected into a parameter vector $\\boldsymbol{\\theta} = \\left [\\beta^{(0)}, \\dots, \\beta^{(C)}) \\right ]^\\top$ and we can solve for all $\\beta$'s simultaneuously. We will be using matrix notation in this example. In matrix form, the generative process is\n",
    "\n",
    "$$\n",
    "    \\mathscr{E} \\triangleq\n",
    "    \\begin{cases}\n",
    "        y^{(i)} = g_{\\mathscr{E}}({{\\boldsymbol{x}^*}^{(i)}}; \\boldsymbol{\\theta}^*) + \\omega_y^*    & \\text{Outcome generation} \\\\\n",
    "        g_{\\mathscr{E}}({{\\boldsymbol{x}^*}^{(i)}}; \\boldsymbol{\\theta}^*) = {{\\boldsymbol{x}^*}^{(i)}}^\\top \\boldsymbol{\\theta^*} & \\text{Linear generating function} \\\\\n",
    "        \\boldsymbol{\\omega}_y^* \\sim \\mathcal{N}(\\mu = 0, \\sigma^2 = 1) & \\text{Gaussian noise} \\\\\n",
    "        \\boldsymbol{\\theta}^* = \\left [{\\beta^*}^{(0)} = 3, {\\beta^*}^{(1)} = 2 \\right ]^\\top & \\text{Linear parameters}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "As we can see, this generative process is different from the one we have been using previously. Instead of being restricted to just 2 parameters, we generalize the function to $P$ parameters.\n",
    "\n",
    "We construct a class to encapsulate the above mathematical notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticEnvironment:\n",
    "    def __init__(self, params: dict) -> None:\n",
    "        self.params = SimpleNamespace(**params)\n",
    "        \n",
    "    def _noise(self):\n",
    "        return np.random.normal(loc=0, scale=self.params.y_star_std)\n",
    "    \n",
    "    def _generating_function(self, x_star: np.array) -> float:\n",
    "        return x_star.T @ self.params.theta_star\n",
    "    \n",
    "    def generate(self, x_star: float) -> float:\n",
    "        x_star = np.insert(x_star, 0, 1)\n",
    "        return self._generating_function(x_star) + self._noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "env_params = {\n",
    "    \"theta_star\"  : np.array([3., 2.]),   # Linear slope and intercept\n",
    "    \"y_star_std\"  : 1.,                   # Standard deviation of sensory data\n",
    "    \"C\"           : 2                     # Number of parameters\n",
    "}\n",
    "\n",
    "# Initialize environment with parameters\n",
    "env = StaticEnvironment(params=env_params)\n",
    "\n",
    "# Generate data\n",
    "N       = 10                                         # Number of samples\n",
    "C       = env_params[\"theta_star\"].shape[0]          # Number of parameters\n",
    "x_range = np.linspace(start=0.01, stop=5, num=500)   # Support of x\n",
    "X_star  = np.random.choice(x_range, size=(N, C-1))   # N random external states\n",
    "y       = np.zeros(N)                                # Empty array for N data samples\n",
    "\n",
    "# Generate N samples\n",
    "for idx, x in enumerate(X_star):\n",
    "    y[idx] = env.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative model is\n",
    "\n",
    "$$\n",
    "    \\mathcal{M} \\triangleq \n",
    "    \\begin{cases}\n",
    "        p_{\\theta, X, \\sigma^2_y}(y^{(i)}) = \\mathcal{N}(y^{(i)}; {\\boldsymbol{x}^{(i)}}^\\top \\boldsymbol{\\theta}, \\sigma^2_y) & \\text{Likelihood} \\\\\n",
    "        \\boldsymbol{\\theta} = \\left [\\beta^{(0)}, \\beta^{(1)} \\right ]^\\top  & \\text{Linear parameters} \\\\\n",
    "        \\phi = \\left \\{\\sigma^2_y \\right \\}  & \\text{Other parameters}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, we have a generating function that is defined $g_{\\mathcal{M}}(\\boldsymbol{X}; \\boldsymbol{\\theta}) = {\\boldsymbol{x}^{(i)}}^\\top \\boldsymbol{\\theta}$, where each sample $x^{(i)}$ is a vector of food sizes (dimension $p$, and with a $1$ inserted in the front of the vector) and $\\theta$ is the parameter vector governing the relationship between the linear combination of $x$ elements. \n",
    "\n",
    "To learn the parameters from the data we use the following equation, the **normal equation**:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} = \\underbrace{(\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T}_{\\text{pseudoinverse}} \\boldsymbol{y} = \\boldsymbol{X}^{+} \\boldsymbol{y}.\n",
    "$$\n",
    "\n",
    "The agent's data consists of $N$ vectors of states of length $P$, $\\mathcal{X} \\triangleq \\left \\{ {\\boldsymbol{x}^*}^{(0)}, \\dots {\\boldsymbol{x}^*}^{(N)} \\right \\}$. Together with $\\mathcal{Y} \\triangleq \\left \\{y^{(0)}, \\dots, y^{(N)} \\right \\}$ we have our dataset $\\mathcal{D} \\triangleq \\left \\{\\mathcal{X}, \\mathcal{Y} \\right \\} = \\left \\{\\boldsymbol{x}^{(i)}, y^{(i)} \\right \\}^N_{i=0}$. \n",
    "\n",
    "The agent must use the state vectors to construct a data matrix $\\boldsymbol{X}$ that we can use in the normal equation. We make a helper function to do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_matrix(X_star: np.ndarray) -> np.ndarray:\n",
    "    return np.insert(X_star, 0, 1, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct our agent. We will use the linear regression agent from notebook 3.1 as our template. Let's start with a minimal agent that just learns parameters. Because we are using the analytic update for maximum likelihood estimation in `mle_theta()`, there is no need for specifying the generative model at all. There are also no parameters as the only thing we are interested in $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegressionAgent:\n",
    "    def __init__(self) -> None:\n",
    "        ...\n",
    "        \n",
    "    def mle_theta(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return np.linalg.pinv(X) @ y\n",
    "    \n",
    "    def build_data_matrix(self, X_star: np.ndarray) -> np.ndarray:\n",
    "        return np.insert(X_star, 0, 1, axis=1) \n",
    "    \n",
    "    def learn_parameters(self, X_star: np.ndarray, y: np.ndarray) -> None:\n",
    "        X = build_data_matrix(self, X_star)\n",
    "        self.theta = self.mle_theta(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to learn the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_star: [3. 2.].\n",
      "theta: [3.898 1.695].\n"
     ]
    }
   ],
   "source": [
    "agent = MultipleLinearRegressionAgent()\n",
    "agent.learn_parameters(X_star, y)\n",
    "theta = agent.theta\n",
    "\n",
    "print(f\"theta_star: {env_params['theta_star']}.\")\n",
    "print(f\"theta: {np.round(theta, 3)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily extend this to a model with five parameters. First we redefine the environment and generate data. We also bump the samples to $N=1000$. With more parameters we want to ensure we have more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "env_params = {\n",
    "    \"theta_star\"  : np.array([3., 2., 4., 5., 6.]), \n",
    "    \"y_star_std\"  : 1.,                   # Standard deviation of sensory data\n",
    "    \"C\"           : 5                     # Number of parameters\n",
    "}\n",
    "\n",
    "# Initialize environment with parameters\n",
    "env = StaticEnvironment(params=env_params)\n",
    "\n",
    "# Generate data \n",
    "N       = 1000                                        # Number of samples\n",
    "C       = env_params[\"theta_star\"].shape[0]          # Number of parameters\n",
    "x_range = np.linspace(start=0.01, stop=5, num=500)   # Support of x\n",
    "X_star  = np.random.choice(x_range, size=(N, C-1))   # N random external states\n",
    "y       = np.zeros(N)                                # Empty array for N data samples\n",
    "\n",
    "# Generate N samples\n",
    "for idx, x in enumerate(X_star):\n",
    "    y[idx] = env.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we learn the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_star: [3. 2. 4. 5. 6.].\n",
      "theta: [2.959 2.023 4.    4.979 6.023].\n"
     ]
    }
   ],
   "source": [
    "agent = MultipleLinearRegressionAgent()\n",
    "agent.learn_parameters(X_star, y)\n",
    "theta = agent.theta\n",
    "\n",
    "print(f\"theta_star: {env_params['theta_star']}.\")\n",
    "print(f\"theta: {np.round(theta, 3)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
